{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Credit Policy</th>\n      <th>Purpose</th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>log_annual_inc</th>\n      <th>dti</th>\n      <th>fico</th>\n      <th>days_with_cr_line</th>\n      <th>revol_bal</th>\n      <th>revol_util</th>\n      <th>inq_last_6mths</th>\n      <th>pub_re</th>\n      <th>delinq_2yrs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>credit card</td>\n      <td>44</td>\n      <td>1</td>\n      <td>9</td>\n      <td>64</td>\n      <td>4</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>debt</td>\n      <td>33</td>\n      <td>1</td>\n      <td>7</td>\n      <td>136</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>debt</td>\n      <td>52</td>\n      <td>1</td>\n      <td>24</td>\n      <td>116</td>\n      <td>1</td>\n      <td>29</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>credit _card</td>\n      <td>33</td>\n      <td>0</td>\n      <td>12</td>\n      <td>33</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>credit _card</td>\n      <td>30</td>\n      <td>1</td>\n      <td>9</td>\n      <td>30</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Credit Policy       Purpose  int_rate  installment  log_annual_inc  dti  \\\n0              2   credit card        44            1               9   64   \n1              3          debt        33            1               7  136   \n2              3          debt        52            1              24  116   \n3              2  credit _card        33            0              12   33   \n4              2  credit _card        30            1               9   30   \n\n   fico  days_with_cr_line  revol_bal  revol_util  inq_last_6mths  pub_re  \\\n0     4                  5          0           0               2       1   \n1     5                  5          0           0               6       4   \n2     1                 29          0           1               2       3   \n3     2                  0          0           1               1       1   \n4     1                  2          0           0               4       3   \n\n   delinq_2yrs  \n0            2  \n1            6  \n2            2  \n3            1  \n4            4  "
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport fancyimpute\nfrom imblearn.pipeline import make_pipeline as imb_make_pipeline\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.ensemble import BalancedBaggingClassifier, EasyEnsemble\nfrom mlens.visualization import corrmat\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\nfrom sklearn.preprocessing import Imputer, RobustScaler, FunctionTransformer\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\nfrom sklearn.ensemble.partial_dependence import plot_partial_dependence\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import (roc_auc_score, confusion_matrix,\n                             accuracy_score, roc_curve,\n                             precision_recall_curve, f1_score)\nfrom sklearn.pipeline import make_pipeline\nimport xgboost as xgb\nfrom keras import models, layers, optimizers\n\nos.chdir(\"../\")\nfrom scripts.plot_roc import plot_roc_and_pr_curves\nos.chdir(\"notebooks/\")\n\n%matplotlib inline\nplt.style.use(\"fivethirtyeight\")\nsns.set_context(\"notebook\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df = pd.read_csv(\"../data/loans.csv\")\n\n# Check both the datatypes and if there is missing values\nprint(f\"\\033[1m\\033[94mData types:\\n{11 * '-'}\")\nprint(f\"\\033[30m{df.dtypes}\\n\")\nprint(f\"\\033[1m\\033[94mSum of null values in each feature:\\n{35 * '-'}\")\nprint(f\"\\033[30m{df.isnull().sum()}\")\ndf.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "pos = df[df[\"not_fully_paid\"] == 1].shape[0]\nneg = df[df[\"not_fully_paid\"] == 0].shape[0]\nprint(f\"Positive examples = {pos}\")\nprint(f\"Negative examples = {neg}\")\nprint(f\"Proportion of positive to negative examples = {(pos / neg) * 100:.2f}%\")\nplt.figure(figsize=(8, 6))\nsns.countplot(df[\"not_fully_paid\"])\nplt.xticks((0, 1), [\"Paid fully\", \"Not paid fully\"])\nplt.xlabel(\"\")\nplt.ylabel(\"Count\")\nplt.title(\"Class counts\", y=1, fontdict={\"fontsize\": 20});"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df = pd.get_dummies(df, columns=[\"purpose\"], drop_first=True)\ndf.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "for feature in df.columns:\n    if np.any(np.isnan(df[feature])):\n        df[\"is_\" + feature + \"_missing\"] = np.isnan(df[feature]) * 1\n\ndf.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "X = df.loc[:, df.columns != \"not_fully_paid\"].values\ny = df.loc[:, df.columns == \"not_fully_paid\"].values.flatten()\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, shuffle=True, random_state=123, stratify=y)\nprint(f\"Original data shapes: {X_train.shape, X_test.shape}\")\n\n# Drop NA and remove binary columns\ntrain_indices_na = np.max(np.isnan(X_train), axis=1)\ntest_indices_na = np.max(np.isnan(X_test), axis=1)\nX_train_dropna, y_train_dropna = X_train[~train_indices_na, :][:, :-6], y_train[~train_indices_na]\nX_test_dropna, y_test_dropna = X_test[~test_indices_na, :][:, :-6], y_test[~test_indices_na]\nprint(f\"After dropping NAs: {X_train_dropna.shape, X_test_dropna.shape}\")\n\n# MICE data\nmice = fancyimpute.MICE(verbose=0)\nX_mice = mice.complete(X)\nX_train_mice, X_test_mice, y_train_mice, y_test_mice = train_test_split(\n    X_mice, y, test_size=0.2, shuffle=True, random_state=123, stratify=y)\nprint(f\"MICE data shapes: {X_train_mice.shape, X_test_mice.shape}\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "rf_clf = RandomForestClassifier(n_estimators=500,\n                                max_features=0.25,\n                                criterion=\"entropy\",\n                                class_weight=\"balanced\")\n# Build base line model -- Drop NA's\npip_baseline = make_pipeline(RobustScaler(), rf_clf)\nscores = cross_val_score(pip_baseline,\n                         X_train_dropna, y_train_dropna,\n                         scoring=\"roc_auc\", cv=10)\nprint(f\"\\033[1m\\033[94mBaseline model's average AUC: {scores.mean():.3f}\")\n\n# Build model with mean imputation\npip_impute_mean = make_pipeline(Imputer(strategy=\"mean\"),\n                                RobustScaler(), rf_clf)\nscores = cross_val_score(pip_impute_mean,\n                         X_train, y_train,\n                         scoring=\"roc_auc\", cv=10)\nprint(f\"\\033[1m\\033[94mMean imputation model's average AUC: {scores.mean():.3f}\")\n\n# Build model with median imputation\npip_impute_median = make_pipeline(Imputer(strategy=\"median\"),\n                                  RobustScaler(), rf_clf)\nscores = cross_val_score(pip_impute_median,\n                         X_train, y_train,\n                         scoring=\"roc_auc\", cv=10)\nprint(f\"\\033[1m\\033[94mMedian imputation model's average AUC: {scores.mean():.3f}\")\n\n# Build model using MICE imputation\npip_impute_mice = make_pipeline(RobustScaler(), rf_clf)\nscores = cross_val_score(pip_impute_mice,\n                         X_train_mice, y_train_mice,\n                         scoring=\"roc_auc\", cv=10)\nprint(f\"\\033[1m\\033[94mMICE imputation model's average AUC: {scores.mean():.3f}\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# fit RF to plot feature importances\nrf_clf.fit(RobustScaler().fit_transform(Imputer(strategy=\"median\").fit_transform(X_train)), y_train)\n\n# Plot features importance\nimportances = rf_clf.feature_importances_\nindices = np.argsort(rf_clf.feature_importances_)[::-1]\nplt.figure(figsize=(12, 6))\nplt.bar(range(1, 25), importances[indices], align=\"center\")\nplt.xticks(range(1, 25), df.columns[df.columns != \"not_fully_paid\"][indices], rotation=90)\nplt.title(\"Feature Importance\", {\"fontsize\": 16});"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Drop generated binary features\nX_train = X_train[:, :-6]\nX_test = X_test[:, :-6]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "rf_clf = RandomForestClassifier(n_estimators=500,\n                                max_features=0.25,\n                                criterion=\"entropy\",\n                                class_weight=\"balanced\")\n\n# Build model with no sampling\npip_orig = make_pipeline(Imputer(strategy=\"mean\"),\n                         RobustScaler(),\n                         rf_clf)\nscores = cross_val_score(pip_orig,\n                         X_train, y_train,\n                         scoring=\"roc_auc\", cv=10)\nprint(f\"\\033[1m\\033[94mOriginal model's average AUC: {scores.mean():.3f}\")\n\n# Build model with undersampling\npip_undersample = imb_make_pipeline(Imputer(strategy=\"mean\"),\n                                    RobustScaler(),\n                                    RandomUnderSampler(), rf_clf)\nscores = cross_val_score(pip_undersample,\n                         X_train, y_train,\n                         scoring=\"roc_auc\", cv=10)\nprint(f\"\\033[1m\\033[94mUnder-sampled model's average AUC: {scores.mean():.3f}\")\n\n# Build model with oversampling\npip_oversample = imb_make_pipeline(Imputer(strategy=\"mean\"),\n                                    RobustScaler(),\n                                    RandomOverSampler(), rf_clf)\nscores = cross_val_score(pip_oversample,\n                         X_train, y_train,\n                         scoring=\"roc_auc\", cv=10)\nprint(f\"\\033[1m\\033[94mOver-sampled model's average AUC: {scores.mean():.3f}\")\n\n# Build model with EasyEnsemble\nresampled_rf = BalancedBaggingClassifier(base_estimator=rf_clf,\n                                         n_estimators=10, random_state=123)\npip_resampled = make_pipeline(Imputer(strategy=\"mean\"),\n                              RobustScaler(), resampled_rf)\n                             \nscores = cross_val_score(pip_resampled,\n                         X_train, y_train,\n                         scoring=\"roc_auc\", cv=10)\nprint(f\"\\033[1m\\033[94mEasyEnsemble model's average AUC: {scores.mean():.3f}\")\n\n# Build model with SMOTE\npip_smote = imb_make_pipeline(Imputer(strategy=\"mean\"),\n                              RobustScaler(),\n                              SMOTE(), rf_clf)\nscores = cross_val_score(pip_smote,\n                         X_train, y_train,\n                         scoring=\"roc_auc\", cv=10)\nprint(f\"\\033[1m\\033[94mSMOTE model's average AUC: {scores.mean():.3f}\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Impute the missing data using features means\nimp = Imputer()\nimp.fit(X_train)\nX_train = imp.transform(X_train)\nX_test = imp.transform(X_test)\n\n# Standardize the data\nstd = RobustScaler()\nstd.fit(X_train)\nX_train = std.transform(X_train)\nX_test = std.transform(X_test)\n\n# Implement RandomUnderSampler\nrandom_undersampler = RandomUnderSampler()\nX_res, y_res = random_undersampler.fit_sample(X_train, y_train)\n# Shuffle the data\nperms = np.random.permutation(X_res.shape[0])\nX_res = X_res[perms]\ny_res = y_res[perms]\nX_res.shape, y_res.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Define base learners\nxgb_clf = xgb.XGBClassifier(objective=\"binary:logistic\",\n                            learning_rate=0.03,\n                            n_estimators=500,\n                            max_depth=1,\n                            subsample=0.4,\n                            random_state=123)\n\nsvm_clf = SVC(gamma=0.1,\n                C=0.01,\n                kernel=\"poly\",\n                degree=3,\n                coef0=10.0,\n                probability=True)\n\nrf_clf = RandomForestClassifier(n_estimators=300,\n                                max_features=\"sqrt\",\n                                criterion=\"gini\",\n                                min_samples_leaf=5,\n                                class_weight=\"balanced\")\n\n# Define meta-learner\nlogreg_clf = LogisticRegression(penalty=\"l2\",\n                                C=100,\n                                fit_intercept=True)\n\n# Fitting voting clf --> average ensemble\nvoting_clf = VotingClassifier([(\"xgb\", xgb_clf),\n                               (\"svm\", svm_clf),\n                               (\"rf\", rf_clf)],\n                              voting=\"soft\",\n                              flatten_transform=True)\nvoting_clf.fit(X_res, y_res)\nxgb_model, svm_model, rf_model = voting_clf.estimators_\nmodels = {\"xgb\": xgb_model, \"svm\": svm_model,\n          \"rf\": rf_model, \"avg_ensemble\": voting_clf}\n\n# Build first stack of base learners\nfirst_stack = make_pipeline(voting_clf,\n                            FunctionTransformer(lambda X: X[:, 1::2]))\n# Use CV to generate meta-features\nmeta_features = cross_val_predict(first_stack,\n                                  X_res, y_res,\n                                  cv=10,\n                                  method=\"transform\")\n# Refit the first stack on the full training set\nfirst_stack.fit(X_res, y_res)\n# Fit the meta learner\nsecond_stack = logreg_clf.fit(meta_features, y_res)\n\n# Plot ROC and PR curves using all models and test data\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\nfor name, model in models.items():\n            model_probs = model.predict_proba(X_test)[:, 1:]\n            model_auc_score = roc_auc_score(y_test, model_probs)\n            fpr, tpr, _ = roc_curve(y_test, model_probs)\n            precision, recall, _ = precision_recall_curve(y_test, model_probs)\n            axes[0].plot(fpr, tpr, label=f\"{name}, auc = {model_auc_score:.3f}\")\n            axes[1].plot(recall, precision, label=f\"{name}\")\nstacked_probs = second_stack.predict_proba(first_stack.transform(X_test))[:, 1:]\nstacked_auc_score = roc_auc_score(y_test, stacked_probs)\nfpr, tpr, _ = roc_curve(y_test, stacked_probs)\nprecision, recall, _ = precision_recall_curve(y_test, stacked_probs)\naxes[0].plot(fpr, tpr, label=f\"stacked_ensemble, auc = {stacked_auc_score:.3f}\")\naxes[1].plot(recall, precision, label=\"stacked_ensembe\")\naxes[0].legend(loc=\"lower right\")\naxes[0].set_xlabel(\"FPR\")\naxes[0].set_ylabel(\"TPR\")\naxes[0].set_title(\"ROC curve\")\naxes[1].legend()\naxes[1].set_xlabel(\"recall\")\naxes[1].set_ylabel(\"precision\")\naxes[1].set_title(\"PR curve\")\nplt.tight_layout()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Plot the correlation between base learners\nprobs_df = pd.DataFrame(meta_features, columns=[\"xgb\", \"svm\", \"rf\"])\ncorrmat(probs_df.corr(), inflate=True);"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "second_stack_probs = second_stack.predict_proba(first_stack.transform(X_test))\nsecond_stack_preds = second_stack.predict(first_stack.transform(X_test))\nconf_mat = confusion_matrix(y_test, second_stack_preds)\n# Define figure size and figure ratios\nplt.figure(figsize=(16, 8))\nplt.matshow(conf_mat, cmap=plt.cm.Reds, alpha=0.2)\nfor i in range(2):\n    for j in range(2):\n        plt.text(x=j, y=i, s=conf_mat[i, j], ha=\"center\", va=\"center\")\nplt.title(\"Confusion matrix\", y=1.1, fontdict={\"fontsize\": 20})\nplt.xlabel(\"Predicted\", fontdict={\"fontsize\": 14})\nplt.ylabel(\"Actual\", fontdict={\"fontsize\": 14});"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Plot partial dependence plots\ngbrt = GradientBoostingClassifier(loss=\"deviance\",\n                                  learning_rate=0.1,\n                                  n_estimators=100,\n                                  max_depth=3,\n                                  random_state=123)\ngbrt.fit(X_res, y_res)\nfig, axes = plot_partial_dependence(gbrt, X_res,\n                                    np.argsort(gbrt.feature_importances_)[::-1][:8],\n                                    n_cols=4,\n                                    feature_names=df.columns[:-6],\n                                    figsize=(14, 8))\nplt.subplots_adjust(top=0.9)\nplt.suptitle(\"Partial dependence plots of borrower not fully paid\\n\"\n             \"the loan based on top most influential features\")\nfor ax in axes: ax.set_xticks(())\nfor ax in [axes[0], axes[4]]: ax.set_ylabel(\"Partial dependence\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}